<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://krishan098.github.io/notes/feed.xml" rel="self" type="application/atom+xml" /><link href="https://krishan098.github.io/notes/" rel="alternate" type="text/html" hreflang="en" /><updated>2025-11-27T15:45:06+00:00</updated><id>https://krishan098.github.io/notes/feed.xml</id><title type="html">Neural Notes</title><subtitle>Notes on Machine Learning, Deep Learning, LangChain, LangGraph, and more.
</subtitle><entry><title type="html">LangGraph Introduction</title><link href="https://krishan098.github.io/notes/blog/2024/langgraph-introduction/" rel="alternate" type="text/html" title="LangGraph Introduction" /><published>2024-02-05T00:00:00+00:00</published><updated>2024-02-05T00:00:00+00:00</updated><id>https://krishan098.github.io/notes/blog/2024/langgraph-introduction</id><content type="html" xml:base="https://krishan098.github.io/notes/blog/2024/langgraph-introduction/"><![CDATA[<h1 id="langgraph">LangGraph</h1>

<ul>
  <li>LangGraph is an orchestration framework for complex agentic systems and is more low-level and controllable than LangChain agents.</li>
</ul>

<h2 id="langgraph-platform-vs-langgraph">LangGraph Platform vs LangGraph</h2>

<ul>
  <li>
    <p>LangGraph is a stateful, orchestration framework that brings added control to agent workflows. LangGraph Platform is a service for deploying and scaling LangGraph applications, with a built-in Studio for prototyping, debugging, and sharing LangGraph applications.</p>
  </li>
  <li>
    <p>A solitary language model is fairly limited</p>
  </li>
</ul>

<p><img src="/notes/assets/img/posts/image.png" alt="" /></p>

<ul>
  <li>So many LLM application use a control flow with steps pre/post-LLM call.</li>
</ul>

<p><img src="/notes/assets/img/posts/image-1.png" alt="" /></p>

<ul>
  <li>This control flow forms a chain</li>
</ul>

<p><img src="/notes/assets/img/posts/image-2.png" alt="" /></p>

<ul>
  <li>
    <p>Agent: control flow defined by a LLM</p>
  </li>
  <li>
    <p>Kinds of agents:</p>

    <ul>
      <li>Router</li>
      <li>Fully Autonomous</li>
    </ul>
  </li>
</ul>

<p><img src="/notes/assets/img/posts/image-3.png" alt="" /></p>]]></content><author><name></name></author><category term="LangGraph" /><category term="langgraph" /><summary type="html"><![CDATA[Notes on LangGraph Introduction]]></summary></entry><entry><title type="html">Vector Stores</title><link href="https://krishan098.github.io/notes/blog/2024/vector-stores/" rel="alternate" type="text/html" title="Vector Stores" /><published>2024-02-04T00:00:00+00:00</published><updated>2024-02-04T00:00:00+00:00</updated><id>https://krishan098.github.io/notes/blog/2024/vector-stores</id><content type="html" xml:base="https://krishan098.github.io/notes/blog/2024/vector-stores/"><![CDATA[<h1 id="vector-stores">Vector Stores</h1>
<ul>
  <li>Vector stores are specialized data stores that enable indexing and retrieving information based on vector representations.</li>
  <li>these vectors are called embeddings, capture the semantic meaning of data that has been embedded.</li>
  <li>Vector stores are frequently used to search over unstructures data, such as text, images and audio, to retrieve relevant information based on semantic similarity rather than exact keyword matches.</li>
</ul>

<p><img src="/notes/assets/img/posts/image-18.png" alt="" /></p>

<h2 id="interface">Interface</h2>

<ul>
  <li>key methods:
    <ul>
      <li>add_documents: add a list of texts to the vector store.</li>
      <li>delete: delete a list of documents from the vector store.</li>
      <li>similarity search: search for similar documents to a given query.</li>
    </ul>
  </li>
</ul>

<h2 id="similarity-search">Similarity search</h2>

<ul>
  <li>
    <p>Given a similarity metric to measure the distance between the embedded query and any embedded document, we need an algorithm to efficiently search over all the embedded documents to find the most similar ones. There are various ways to do this. As an example, many vectorstores implement HNSW (Hierarchical Navigable Small World), a graph-based index structure that allows for efficient similarity search. Regardless of the search algorithm used under the hood, the LangChain vectorstore interface has a similarity_search method for all integrations.</p>
  </li>
  <li>
    <p>similarity search has the following parameters:</p>
    <ul>
      <li>query: text to look up documents similar to.</li>
      <li>k: number of documents to return</li>
      <li>filter: Dictionary of arguments to filter on metadata.</li>
    </ul>
  </li>
</ul>

<h2 id="metadata-filtering">Metadata filtering</h2>
<ul>
  <li>Metadata filtering helps narrow down the search by applying specific conditions such as retrieving documents from a particular source or date range.</li>
  <li>These 2 concepts work well together:
    <ol>
      <li>Swmantic search: Query the unstructured data directly, often via embedding or keyword similarity.</li>
      <li>Metadata search: Apply structured query to the metadata, filtering specific documents.</li>
    </ol>
  </li>
</ul>

<h2 id="advanced-search-and-retrieval-techniques">Advanced search and retrieval techniques:</h2>

<ul>
  <li>
    <p>While algorithms like HNSW provide the foundation for efficient similarity search in many cases, additional techniques can be employed to improve search quality and diversity.</p>
  </li>
  <li>
    <p>hybrid search: hybrid search combines keyword and semantic similarity, marrying the benefits of both approaches.</p>
  </li>
  <li>
    <p>Maximal Marginal Relevance: MMR attempts to diversify the results of a search to avoid returning similar and redundant documents.</p>
  </li>
</ul>

<h2 id="reference">Reference</h2>
<ul>
  <li><a href="https://www.pinecone.io/learn/series/faiss/hnsw/">HNSW</a></li>
</ul>]]></content><author><name></name></author><category term="LangChain" /><category term="RAG" /><category term="langchain" /><category term="rag" /><summary type="html"><![CDATA[Notes on Vector Stores]]></summary></entry><entry><title type="html">Tool Calling</title><link href="https://krishan098.github.io/notes/blog/2024/tool-calling/" rel="alternate" type="text/html" title="Tool Calling" /><published>2024-02-03T00:00:00+00:00</published><updated>2024-02-03T00:00:00+00:00</updated><id>https://krishan098.github.io/notes/blog/2024/tool-calling</id><content type="html" xml:base="https://krishan098.github.io/notes/blog/2024/tool-calling/"><![CDATA[<h1 id="tool-callingfunction-calling">Tool Calling/Function calling</h1>

<ul>
  <li>Many AI applications interact directly with humans. In these cases, it is appropriate for models to respond in natural language. But what about cases where we want a model to also interact directly with systems, such as databases or an API? These systems often have a particular input schema; for example, APIs frequently have a required payload structure. This need motivates the concept of tool calling.</li>
</ul>

<p><img src="/notes/assets/img/posts/image-13.png" alt="" /></p>

<h2 id="key-concepts">Key concepts:</h2>

<ol>
  <li>
    <p>Tool Creation: use the @tool decorator to create a tool. A tool is an association between a function and it’s schema.</p>
  </li>
  <li>
    <p>Tool Binding: The tool needs to be connected to a model that supports tool calling. This gives the model awareness of the tool and the associated input schema required by the tool.</p>
  </li>
  <li>
    <p>Tool Calling: When appropriate, the model can decide to call a tool and ensure its response conforms the tool’s input schema.</p>
  </li>
  <li>
    <p>Tool Execution: The tool can be executed using the arguments provided by the model.</p>
  </li>
</ol>

<p><img src="/notes/assets/img/posts/image-14.png" alt="" /></p>

<h2 id="tool-calling">Tool calling</h2>
<p><img src="/notes/assets/img/posts/image-15.png" alt="" /></p>

<ul>
  <li>A key principle of tool calling is that the model decides when to use a tool based on the input’s relevance. The model doesn’t always need to call a tool.</li>
</ul>

<h2 id="tool-execution">Tool execution</h2>
<ul>
  <li>they can be directly invoked</li>
</ul>

<h2 id="reference">Reference</h2>
<p><a href="https://python.langchain.com/docs/concepts/tool_calling/">tool-calling</a>
<a href="https://platform.openai.com/docs/guides/function-calling/example-use-cases?api-mode=responses">function-calling</a></p>]]></content><author><name></name></author><category term="LangChain" /><category term="RAG" /><category term="langchain" /><category term="rag" /><summary type="html"><![CDATA[Notes on Tool Calling]]></summary></entry><entry><title type="html">Tools</title><link href="https://krishan098.github.io/notes/blog/2024/tools/" rel="alternate" type="text/html" title="Tools" /><published>2024-02-02T00:00:00+00:00</published><updated>2024-02-02T00:00:00+00:00</updated><id>https://krishan098.github.io/notes/blog/2024/tools</id><content type="html" xml:base="https://krishan098.github.io/notes/blog/2024/tools/"><![CDATA[<h1 id="tools">TOOLS</h1>
<ul>
  <li>The tool abstraction in LangChain associates a Python function with a schema that defines the function’s name, description and expected arguments.</li>
</ul>

<h2 id="key-concepts">Key Concepts:</h2>
<ul>
  <li>Tools are a way to encapsulate a function and its schema in a way that can be passed to a chat model.</li>
  <li>Create tools using the @tool decorator, which simplifies the process of tool creation, supporting the following:
    <ul>
      <li>Automatically infer the tool’s name, description and expected arguments, while also supporting customization.</li>
      <li>Defining tools that return artifacts.</li>
      <li>Hiding input arguments from the schema using injected tool arguments.
        <h2 id="tool-interface">Tool Interface:</h2>
      </li>
    </ul>
  </li>
  <li>key attributes:
    <ul>
      <li>name: name of the tool</li>
      <li>description: a description of what the tool does.</li>
      <li>args: Property that returns the JSON schema for the tool’s arguments.</li>
    </ul>
  </li>
  <li>key methods to execute function associated with the tool:
    <ul>
      <li>invoke: invoke the tool with given arguments.</li>
      <li>ainvoke: invokes the tool with the given arguments, asynchronously.
        <h2 id="tool-artifacts">Tool Artifacts:</h2>
      </li>
    </ul>
  </li>
  <li>Tools are utilities that can be called by a model, and whose outputs are designed to be fed back to a model. Sometimes, however, there are artifacts of a tool’s execution that we want to make accessible to downstream components in our chain or agent, but that we don’t want to expose to the model itself. For example if a tool returns a custom object, a dataframe or an image, we may want to pass some metadata about this output to the model without passing the actual output to the model. At the same time, we may want to be able to access this full output elsewhere, for example in downstream tools.</li>
</ul>

<h3 id="reference">Reference</h3>
<p><a href="https://python.langchain.com/docs/concepts/tools/">tools</a></p>]]></content><author><name></name></author><category term="LangChain" /><category term="RAG" /><category term="langchain" /><category term="rag" /><summary type="html"><![CDATA[Notes on Tools]]></summary></entry><entry><title type="html">Tokens</title><link href="https://krishan098.github.io/notes/blog/2024/tokens/" rel="alternate" type="text/html" title="Tokens" /><published>2024-02-01T00:00:00+00:00</published><updated>2024-02-01T00:00:00+00:00</updated><id>https://krishan098.github.io/notes/blog/2024/tokens</id><content type="html" xml:base="https://krishan098.github.io/notes/blog/2024/tokens/"><![CDATA[<h1 id="tokens">TOKENS</h1>
<h2 id="references">References</h2>
<ul>
  <li>python.langchain.com/docs/how_to/split_by_token/</li>
  <li>https://python.langchain.com/docs/concepts/tokens/</li>
</ul>]]></content><author><name></name></author><category term="LangChain" /><category term="RAG" /><category term="langchain" /><category term="rag" /><summary type="html"><![CDATA[Notes on Tokens]]></summary></entry><entry><title type="html">Text splitters</title><link href="https://krishan098.github.io/notes/blog/2024/text-splitters/" rel="alternate" type="text/html" title="Text splitters" /><published>2024-01-31T00:00:00+00:00</published><updated>2024-01-31T00:00:00+00:00</updated><id>https://krishan098.github.io/notes/blog/2024/text-splitters</id><content type="html" xml:base="https://krishan098.github.io/notes/blog/2024/text-splitters/"><![CDATA[<h1 id="text-splitters">Text Splitters</h1>

<h2 id="overview">Overview</h2>
<ul>
  <li>Document splitting is often a crucial preprocessing step.</li>
  <li>It invoves breaking down large texts into smaller, manageable chunks. This process offers several benefits, such as ensuring consistent processing of varying document lengths, overcoming input size of limitations of models and improving the quality of text representations used in retrieval systems.</li>
</ul>

<h2 id="key-concepts">Key concepts</h2>
<p><img src="/notes/assets/img/posts/image-17.png" alt="" /></p>
<ul>
  <li>Text splitters split documents into smaller chunks for use in downstream applications.</li>
</ul>

<h2 id="why-split-documents">Why split documents</h2>

<ul>
  <li>
    <p>handling non-uniform document lengths: splitting ensures consistent processing across all documents.</p>
  </li>
  <li>
    <p>overcoming model limitations: splitting allows us to process documents that would otherwise exceed these limits.</p>
  </li>
  <li>
    <p>Improving representation quality: Splitting can lead to more focused and accurate representations of each section.</p>
  </li>
  <li>
    <p>Enhancing retrieval precision: Splitting allows for more precise matching of queries to relevant document sections.</p>
  </li>
  <li>
    <p>Optimizing computational resources: working with smaller chunks of text can be more memory-efficient and allow for better parallelization of processing tasks.</p>
  </li>
</ul>

<h2 id="approaches">Approaches</h2>

<h3 id="length-based">Length-based</h3>
<ul>
  <li>splits on the basis of document’s length.</li>
  <li>each chunk doesn’t exceed a specified size limit.</li>
  <li>benefits
    <ul>
      <li>straightforward implementation</li>
      <li>consistent chunk sizes</li>
      <li>easily adaptable to different models</li>
    </ul>
  </li>
  <li>types:
    <ul>
      <li>Token-based: splits text based ont the number of tokens, which is useful when working with language models.</li>
      <li>Character-based: Splits text based on the number of characters, which can be more consistent across different types of text.</li>
    </ul>
  </li>
  <li>
    <p>Text-structured based</p>
  </li>
  <li>
    <p>Text is naturally organized into hierarchical units such as paragraphs, sentences, and words. We can leverage this inherent structure to inform our splitting strategy, creating split that maintain natural language flow, maintain semantic coherence within split, and adapts to varying levels of text granularity. LangChain’s RecursiveCharacterTextSplitter implements this concept:</p>

    <ul>
      <li>The RecursiveCharacterTextSplitter attempts to keep larger units (e.g., paragraphs) intact.</li>
      <li>If a unit exceeds the chunk size, it moves to the next level (e.g., sentences).</li>
      <li>This process continues down to the word level if necessary.</li>
    </ul>
  </li>
  <li>Document-structured based</li>
  <li>
    <p>Some documents have an inherent structure, such as HTML, Markdown, or JSON files. In these cases, it’s beneficial to split the document based on its structure, as it often naturally groups semantically related text. Key benefits of structure-based splitting:</p>

    <ul>
      <li>Preserves the logical organization of the document</li>
      <li>Maintains context within each chunk</li>
      <li>Can be more effective for downstream tasks like retrieval or summarization</li>
    </ul>
  </li>
  <li>
    <p>Examples of structure-based splitting:</p>

    <ul>
      <li>Markdown: Split based on headers (e.g., #, ##, ###)</li>
      <li>HTML: Split using tags</li>
      <li>JSON: Split by object or array elements</li>
      <li>Code: Split by functions, classes, or logical blocks</li>
    </ul>
  </li>
</ul>

<h1 id="semantic-meaning-based">Semantic meaning based</h1>

<ul>
  <li>
    <p>Unlike the previous methods, semantic-based splitting actually considers the content of the text. While other approaches use document or text structure as proxies for semantic meaning, this method directly analyzes the text’s semantics. There are several ways to implement this, but conceptually the approach is split text when there are significant changes in text meaning. As an example, we can use a sliding window approach to generate embeddings, and compare the embeddings to find significant differences:</p>

    <ul>
      <li>Start with the first few sentences and generate an embedding.</li>
      <li>Move to the next group of sentences and generate another embedding (e.g., using a sliding window approach).</li>
      <li>Compare the embeddings to find significant differences, which indicate potential “break points” between semantic sections.</li>
    </ul>
  </li>
  <li>
    <p>This technique helps create chunks that are more semantically coherent, potentially improving the quality of downstream tasks like retrieval or summarization.</p>
  </li>
</ul>

<h2 id="references">References</h2>
<ul>
  <li><a href="https://python.langchain.com/docs/concepts/text_splitters/">textsplitters</a></li>
  <li><a href="https://github.com/FullStackRetrieval-com/RetrievalTutorials/blob/main/tutorials/LevelsOfTextSplitting/5_Levels_Of_Text_Splitting.ipynb">notebook</a></li>
</ul>]]></content><author><name></name></author><category term="LangChain" /><category term="RAG" /><category term="langchain" /><category term="rag" /><summary type="html"><![CDATA[Notes on Text splitters]]></summary></entry><entry><title type="html">Subgraphs</title><link href="https://krishan098.github.io/notes/blog/2024/subgraphs/" rel="alternate" type="text/html" title="Subgraphs" /><published>2024-01-30T00:00:00+00:00</published><updated>2024-01-30T00:00:00+00:00</updated><id>https://krishan098.github.io/notes/blog/2024/subgraphs</id><content type="html" xml:base="https://krishan098.github.io/notes/blog/2024/subgraphs/"><![CDATA[<h1 id="subgraphs">Subgraphs</h1>
<ul>
  <li>A subgraph is a graph that is used as a node in another graph.</li>
  <li>encapsulation applied to LangGraph.</li>
  <li>
    <p>allows to build complex systems with multiple components that are themselves graphs.
<img src="/notes/assets/img/posts/image-3.png" alt="" /></p>
  </li>
  <li>Some reasons for using subgraphs are:</li>
</ul>

<ol>
  <li>building multi-agent systems</li>
  <li>when you want to reuse a set of nodes in multiple graphs</li>
  <li>when you want different teams to work on different parts of the graph independently, you can define each part as a subgraph, and as long as the subgraph interface (the input and output schemas) is respected, the parent graph can be built without knowing any details of the subgraph</li>
</ol>

<h2 id="ways-that-the-parent-and-subgraph-communicate-">ways that the parent and subgraph communicate :</h2>

<ol>
  <li>parent and subgraph have shared state keys in their state schemas.
    <ul>
      <li>we can include the subgraph as a node in the parent graph.</li>
    </ul>
  </li>
  <li>parent and subgraph have different schema.
    <ul>
      <li>call the subgraph from inside a node in the parent graph.</li>
    </ul>
  </li>
</ol>

<p>For reference:
https://langchain-ai.github.io/langgraph/concepts/subgraphs/</p>]]></content><author><name></name></author><category term="LangChain" /><category term="RAG" /><category term="langchain" /><category term="rag" /><summary type="html"><![CDATA[Notes on Subgraphs]]></summary></entry><entry><title type="html">Streaming</title><link href="https://krishan098.github.io/notes/blog/2024/streaming/" rel="alternate" type="text/html" title="Streaming" /><published>2024-01-29T00:00:00+00:00</published><updated>2024-01-29T00:00:00+00:00</updated><id>https://krishan098.github.io/notes/blog/2024/streaming</id><content type="html" xml:base="https://krishan098.github.io/notes/blog/2024/streaming/"><![CDATA[<h1 id="streaming">Streaming</h1>
<ul>
  <li>https://python.langchain.com/docs/concepts/streaming/</li>
</ul>]]></content><author><name></name></author><category term="LangChain" /><category term="RAG" /><category term="langchain" /><category term="rag" /><summary type="html"><![CDATA[Notes on Streaming]]></summary></entry><entry><title type="html">Runnable interface</title><link href="https://krishan098.github.io/notes/blog/2024/runnable-interface/" rel="alternate" type="text/html" title="Runnable interface" /><published>2024-01-28T00:00:00+00:00</published><updated>2024-01-28T00:00:00+00:00</updated><id>https://krishan098.github.io/notes/blog/2024/runnable-interface</id><content type="html" xml:base="https://krishan098.github.io/notes/blog/2024/runnable-interface/"><![CDATA[<h1 id="runnable-interface">Runnable interface</h1>
<ul>
  <li>https://python.langchain.com/docs/concepts/runnables/</li>
</ul>]]></content><author><name></name></author><category term="LangChain" /><category term="RAG" /><category term="langchain" /><category term="rag" /><summary type="html"><![CDATA[Notes on Runnable interface]]></summary></entry><entry><title type="html">Retrieval</title><link href="https://krishan098.github.io/notes/blog/2024/retrieval/" rel="alternate" type="text/html" title="Retrieval" /><published>2024-01-27T00:00:00+00:00</published><updated>2024-01-27T00:00:00+00:00</updated><id>https://krishan098.github.io/notes/blog/2024/retrieval</id><content type="html" xml:base="https://krishan098.github.io/notes/blog/2024/retrieval/"><![CDATA[<h1 id="retrieval">Retrieval</h1>

<h2 id="overview">Overview</h2>

<ul>
  <li>Retrieval systems are fundamental to many AI applications, efficiently identifying relevant information from large datasets. These systems accomodate various data formats:</li>
</ul>

<ol>
  <li>
    <p>Unstructured text is often stored in vector stores or lexical search indexes.</p>
  </li>
  <li>
    <p>Structured data is typically housed in relational or graph databases with defined schemas.</p>
  </li>
</ol>

<h2 id="key-concepts">Key concepts</h2>

<ul>
  <li><img src="/notes/assets/img/posts/image-8.png" alt="" /></li>
</ul>

<ol>
  <li>
    <p>Query analysis: A process where models transform or construct search queries to optimise retrieval.</p>
  </li>
  <li>
    <p>Information retrieval: Search queries are used to fetch information from various retrieval systems</p>
  </li>
</ol>

<h2 id="query-analysis">Query Analysis</h2>

<ul>
  <li>It serves as a bridge between raw user input and optimized search queries.Common applications include:</li>
</ul>

<ol>
  <li>
    <p>Query Re-writing: Queries can be re-written or expanded to improve semantic or lexical searches.</p>
  </li>
  <li>
    <p>Query construction: Search indexes may require structured queries.</p>
  </li>
</ol>

<h3 id="query-re-writing">Query re-writing</h3>

<ul>
  <li>Retrieval systems should ideally handle a wide spectrum of user inputs, from simple and poorly worded queries to complex, multi-faced questions. To achieve this veratility, a popular approach is to use models to transform raw user queries into more effective search queries.</li>
</ul>

<ol>
  <li>
    <p>Query Clarification: Models can rephrase ambiguous or poorly worded queries for clarity.</p>
  </li>
  <li>
    <p>Semantic Understanding: They can capture the intent behind a query, going beyond literal keyword matching.</p>
  </li>
  <li>
    <p>Query Expansion: Models can generate related terms or concepts to broaden the search scope.</p>
  </li>
  <li>
    <p>Complex query handling: They can break down multi-part questions into simpler sub-queries.</p>
  </li>
</ol>

<h4 id="various-techniques">Various techniques:</h4>

<ol>
  <li>
    <p>Multi-query: When you want to ensure high recall in retrieval by providing multiple phrasings of a question, rewrite the user question with multiple phrasings, retrieve documents for each rewritten question, return the unique documents for all queries.</p>
  </li>
  <li>
    <p>Decomposition: Decompose a question into a set of subproblems/ questions, which can either be solved sequentially or in parallel.</p>
  </li>
  <li>
    <p>Step back : First prompt the LLM to ask a generic step-back question about higher-level concepts or principles, and retrieve relevant facts about them.</p>
  </li>
  <li>
    <p>HyDE: Use an LLM to convert questions into hypothetical documents that answer the question. Use the embedded hypothetical documents to retrieve real documents with the premise that doc-doc similarity search can produce more relevant matches.</p>
    <h3 id="query-construction">Query construction</h3>
  </li>
</ol>

<ul>
  <li>Query analysis can focus on translating natural language queries into specialized query languages or filters. This translation is crucial for effectively interacting with various types of databases that house structured or semi-structured data.</li>
</ul>

<ol>
  <li>Structured data examples: For relational and graph databases, domain-specific languages are used to query data.</li>
</ol>

<ul>
  <li>text-to-SQL</li>
  <li>Text-to-cypher</li>
</ul>

<ol>
  <li>Semi-structured data examples: for vectorstores, queries can combine semantic search with metadata filtering.</li>
</ol>

<ul>
  <li>Natural language to Metadata filters: converts user queries into appropriate metadata filters.</li>
</ul>

<h4 id="popular-techniques">Popular techniques</h4>

<ul>
  <li>
    <p>Self query: This uses an LLM to transform user input into 2 things: 1. a string to look up semantically, 2. a metadata filter to go along with it.</p>
  </li>
  <li>
    <p>Text-to-SQL: This uses an LLM to transform user input to a SQL query</p>
  </li>
  <li>
    <p>Text-to-cypher: This uses an LLM to transform user into a Cypher query.</p>
  </li>
</ul>

<h2 id="information-retrieval">Information retrieval</h2>

<h3 id="common-retrieval-systems">Common retrieval systems</h3>

<h4 id="lexical-search-indexes">Lexical search indexes</h4>
<ul>
  <li>
    <p>Many search engines are based upon matching words in a query to the words in each document. This approach is called lexical retrieval. depends on word’s frequency in query and the doc.</p>
  </li>
  <li>
    <p>The particular data structure used to implement this is often an inverted index.(In an inverted index, the index is organised by terms(words) and each term points to a list of documents or web pages that contain that term.)</p>
  </li>
  <li>
    <p>An inverted index is an index data structure storing a mapping from content, such as words or numbers, to its location in a document or a set of documents.</p>
  </li>
</ul>

<p><img src="/notes/assets/img/posts/image-9.png" alt="" /></p>

<h4 id="vector-indexes">Vector indexes</h4>

<ul>
  <li>Vectorstores use an embedding model to compress documents into high-dimensional vector representation. This allows for efficient similarity search over embedding vectors using simple mathematical operations like cosine similarity.</li>
</ul>

<h4 id="relational-databases">Relational databases</h4>

<ul>
  <li>Relational databases are a fundamental type of structured data storage used in many applications. They organize data into tables with predefined schemas, where each table represents an entity or relationship. Data is stored in rows (records) and columns (attributes), allowing for efficient querying and manipulation through SQL (Structured Query Language). Relational databases excel at maintaining data integrity, supporting complex queries, and handling relationships between different data entities.</li>
</ul>

<h4 id="graph-database">Graph database</h4>

<ul>
  <li>Graph databases are a specialized type of database designed to store and manage highly interconnected data. Unlike traditional relational databases, graph databases use a flexible structure consisting of nodes (entities), edges (relationships), and properties. This structure allows for efficient representation and querying of complex, interconnected data. Graph databases store data in a graph structure, with nodes, edges, and properties. They are particularly useful for storing and querying complex relationships between data points, such as social networks, supply-chain management, fraud detection, and recommendation services</li>
</ul>

<h2 id="retriever">Retriever</h2>

<ol>
  <li>input: a query</li>
  <li>Output: a list of documents</li>
</ol>

<p><img src="/notes/assets/img/posts/image-11.png" alt="" /></p>

<ul>
  <li>The only requirement for a retriever is the ability to accepts a query and return documents. In particular, LangChain’s retriever class only requires that the _get_relevant_documents method is implemented, which takes a query: str and returns a list of Document objects that are most relevant to the query. The underlying logic used to get relevant documents is specified by the retriever and can be whatever is most useful for the application.</li>
</ul>

<h3 id="common-types">Common types</h3>

<h4 id="search-apis">Search apis</h4>

<ul>
  <li>We can build retrievers on top of search APIs that simply return search results. (Amazon kendra or Wikipidea Search)</li>
</ul>

<h4 id="relational-or-graph-database">Relational or graph database</h4>

<ul>
  <li>Retrievers can be built on top of relational or graph databases. In these cases, query analysis techniques to construct a structured query from natural language is critical. For example, you can build a retriever for a SQL database using text-to-SQL conversion. This allows a natural language query (string) retriever to be transformed into a SQL query behind the scenes.</li>
</ul>

<h4 id="lexical-search">Lexical search</h4>

<ul>
  <li>BM25 and TF-IDF</li>
</ul>

<h4 id="vector-store">Vector store</h4>

<ul>
  <li>Efficient way to index and retrieve unstructured data.</li>
</ul>

<h3 id="advanced-retrieval-patterns">Advanced retrieval patterns</h3>

<h4 id="ensemble">Ensemble:</h4>

<ul>
  <li>
    <p>possible to combine multiple retrievers</p>
  </li>
  <li>
    <p>useful when multiple retrievers that are good at finding different types of relevant documents are used.</p>
  </li>
  <li>
    <p>re-ranking: takes output of multiple retrievers and combine them using a more sophisticated algorithm such as reciprocal rank fusion.</p>
  </li>
</ul>

<h4 id="source-document-retention">Source document retention</h4>

<ul>
  <li>
    <p>Many retrievers utilize some kind of index to make documents easily searchable.</p>
  </li>
  <li>
    <p>The process of indexing can include a transformation step.(vectorstores use document splitting)
<img src="/notes/assets/img/posts/image-12.png" alt="" /></p>
  </li>
  <li>
    <p>it ensures no loss in document context for the model.</p>
  </li>
</ul>

<h5 id="two-types-of-retrievers">two types of retrievers:</h5>

<ol>
  <li>
    <p>Parent document(vector store  +document store): doesn’t use an LLM; involves indexing multiple chunks for each document. most similar chunks are found iin embedding space, but we retrieve th ewhole parent document and return that.</p>
  </li>
  <li>
    <p>Multi Vector: uses LLM sometimes during indexing; creates multiple vectors for each document.</p>
  </li>
</ol>

<h2 id="reference">Reference</h2>
<ul>
  <li>
    <p>https://python.langchain.com/docs/concepts/retrievers/</p>
  </li>
  <li>
    <p>https://python.langchain.com/docs/concepts/retrieval/</p>
  </li>
</ul>]]></content><author><name></name></author><category term="LangChain" /><category term="RAG" /><category term="langchain" /><category term="rag" /><summary type="html"><![CDATA[Notes on Retrieval]]></summary></entry></feed>