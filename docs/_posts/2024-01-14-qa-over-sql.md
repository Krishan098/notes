---
layout: post
title: "Q&A Over SQL"
date: 2024-01-14
description: Notes on Q&A Over SQL
tags: [langchain, q&a-over-sql]
categories: [LangChain, Q&A Over SQL]
---

# Build a Question/Answering system over SQL data

- q&a system over tabular data in databases

## Architecture

- At a high level, the steps of these systems are:

    1. Convert question to SQL query: model converts user input to a SQL query

    2. Execute SQL query

    3. Answer the question

![](/notes/assets/img/posts/image.png)
m
## Chains 

- chains are compositions of predictable steps.

- we can represent a chain via simple squence of nodes.

## Application State

- The LangGraph state of our application controls what data is input to the application, transferred between steps and output by the application.

## Convert question to SQL query

- the first step is to the user input and convert it to a SQL query.

### SQLDATABASE

- dialect: return string representation of dialect to use

- table_info: information about all tables in the database.

## Execute query

- loads a tool from langchain_community

- most dangerous part of creating a sql chain. Minimize the database connection permissions as much as possible.

## Generate Answer

- Finally, our last step generates an answer to the question given the information pulled from the database:

## Human-in-the-loop

- HIL workflows enable human intervention at any point in an automated process.

### key capabilities



- Persistent execution state: LangGraph checkpoints the graph state after each step, allowing execution to pause indefinitely at defined nodes. This supports asynchronous human review or input without time constraints.

- Flexible integration points: HIL logic can be introduced at any point in the workflow. This allows targeted human involvement, such as approving API calls, correcting outputs, or guiding conversations.

### Typical use cases¬∂

- üõ†Ô∏è Reviewing tool calls: Humans can review, edit, or approve tool calls requested by the LLM before tool execution.

- ‚úÖ Validating LLM outputs: Humans can review, edit, or approve content generated by the LLM.

- üí° Providing context: Enable the LLM to explicitly request human input for clarification or additional details or to support multi-turn conversations.

### Implementation¬∂

- interrupt function: Pauses execution at a specific point, presents information for human review.
    
- Command primitive: Used to resume execution with a value provided by the human.

## Persistence

- LangGraph has a built-in persistence layer, implemented through checkpointers. When you compile graph with a checkpointer, the checkpointer saves a checkpoint of the graph state at every super-step. Those checkpoints are saved to a thread, which can be accessed after graph execution. Because threads allow access to graph's state after execution, several powerful capabilities including human-in-the-loop, memory, time travel, and fault-tolerance are all possible. 
![](/notes/assets/img/posts/image-1.png)

- Threads: A thread is a unique ID assigned to each checkpoint saved by a checkpointer.

- Checkpoints: It is a snapshot of the graph state saved at each super-step and is represented by StateSnapshot object.

- InMemorySaver: this checkpoint saver stores checkpoints in memory using a defaultdict.

## Agents

- By themselves, language models can't take actions - they just output text. Agents are systems that take a high-level task and use an LLM as a reasoning engine to decide what actions to take and execute those actions.

- Using agents allows you to offload additional discretion over the query generation and execution process. Although their behavior is less predictable than the above "chain", they feature some advantages:

- - They can query the database as many times as needed to answer the user question.

- - They can recover from errors by running a generated query, catching the traceback and regenerating it correctly.

- - They can answer questions based on the databases' schema as well as on the databases' content (like describing a specific table).

## Dealing with high-cardinality columns

- In order to filter columns that contain proper nouns such as addresses, song names or artists, we first need to double-check the spelling in order to filter the data correctly.

- We can achieve this by creating a vector store with all the distinct proper nouns that exist in the database. We can then have the agent query that vector store each time the user includes a proper noun in their question, to find the correct spelling for that word. In this way, the agent can make sure it understands which entity the user is referring to before building the target query.