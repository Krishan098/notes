<!DOCTYPE html>
<html lang="en">
  <!-- Head -->
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    
    <!-- Metadata, OpenGraph and Schema.org -->




<!-- Standard metadata -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<title>
  
  
    
      Chat Models | Neural Notes
    
  
</title>
<meta name="author" content="Neural Notes">
<meta name="description" content="Notes on Chat Models">

  <meta name="keywords" content="machine-learning, deep-learning, langchain, langgraph, notes">






  <!-- OpenGraph -->
  <meta property="og:site_name" content="Neural Notes">
  <meta property="og:type" content="article">
  <meta property="og:title" content="Neural Notes | Chat Models">
  <meta property="og:url" content="https://krishan098.github.io/notes/blog/2024/chat-models/">
  <meta property="og:description" content="Notes on Chat Models">
  
  <meta property="og:locale" content="en">

  <!-- Twitter card -->
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Chat Models">
  <meta name="twitter:description" content="Notes on Chat Models">
  
  



  <!-- Schema.org -->
  
  
  

  <script type="application/ld+json">
    {
        "author":
        {
            "@type": "Person",
            "name": "Neural Notes"
        },
        "url": "https://krishan098.github.io/notes/blog/2024/chat-models/",
        "@type": "BlogPosting",
        "description": "Notes on Chat Models",
        "headline": "Chat Models",
        
        "sameAs": ["https://github.com/Krishan098"],
        
        "name": "Neural Notes",
        "@context": "https://schema.org"
    }
  </script>



<!-- Bootstrap & MDB -->
<link rel="stylesheet" href="/notes/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous">



<!-- Fonts & Icons -->
<link defer rel="stylesheet" href="/notes/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5">
<link defer rel="stylesheet" href="/notes/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772">
<link defer rel="stylesheet" type="text/css" href="">

<!-- Code Syntax Highlighting -->
<link defer rel="stylesheet" href="/notes/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light">


  <!-- Sidebar Table of Contents -->
  <link defer href="/notes/assets/css/bootstrap-toc.min.css?6f5af0bb9aab25d79b2448143cbeaa88" rel="stylesheet">


<!-- Styles -->




  <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%93%9D&lt;/text&gt;&lt;/svg&gt;">

<link rel="stylesheet" href="/notes/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e">
<link rel="canonical" href="https://krishan098.github.io/notes/blog/2024/chat-models/">


  <!-- Dark Mode -->
  <script src="/notes/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script>
  <link defer rel="stylesheet" href="/notes/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark">
  <script>
    initTheme();
  </script>










  </head>

  <!-- Body -->
  <body class="fixed-top-nav sticky-bottom-footer">
    <!-- Header -->
    <header>
  <!-- Nav Bar -->
  <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation">
    <div class="container">
      
        <a class="navbar-brand title font-weight-lighter" href="/notes/">
          Neural Notes
        </a>
      
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>

      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          

          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/notes/">About
              
            </a>
          </li>

          <!-- Other pages -->
          
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
              
                
                <li class="nav-item active">
                  <a class="nav-link" href="/notes/blog/">blog
                    
                  </a>
                </li>
              
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
          
            <!-- Search -->
            <li class="nav-item">
              <button id="search-toggle" title="Search" onclick="openSearchModal()">
                <span class="nav-link">ctrl k <i class="ti ti-search"></i></span>
              </button>
            </li>
          
          
            <!-- Toogle theme mode -->
            <li class="toggle-container">
              <button id="light-toggle" title="Change theme">
                <i class="ti ti-sun-moon" id="light-toggle-system"></i>
                <i class="ti ti-moon-filled" id="light-toggle-dark"></i>
                <i class="ti ti-sun-filled" id="light-toggle-light"></i>
              </button>
            </li>
          
        </ul>
      </div>
    </div>
  </nav>
  
    <!-- Scrolling Progress Bar -->
    <progress id="progress" value="0">
      <div class="progress-container">
        <span class="progress-bar"></span>
      </div>
    </progress>
  
</header>


    <!-- Content -->
    <div class="container mt-5" role="main">
      
        
          <div class="row">
            <!-- sidebar, which will move to the top on a small screen -->
            <div class="col-sm-3">
              <nav id="toc-sidebar" class="sticky-top"></nav>
            </div>
            <!-- main content area -->
            <div class="col-sm-9">






<div class="post">
  <header class="post-header">
    <h1 class="post-title">Chat Models</h1>
    <p class="post-meta">
      Created on January 20, 2024
      
      
      
    </p>
    <p class="post-tags">
      
        <a href="/notes/blog/2024"> <i class="fa-solid fa-calendar fa-sm"></i> 2024 </a>
      
      
          ·  
        
          
            <a href="/notes/blog/tag/langchain"> <i class="fa-solid fa-hashtag fa-sm"></i> langchain</a>
          
          
             
          
        
          
            <a href="/notes/blog/tag/rag"> <i class="fa-solid fa-hashtag fa-sm"></i> rag</a>
          
          
        
      

      
          ·  
        
          
            <a href="/notes/blog/category/langchain"> <i class="fa-solid fa-tag fa-sm"></i> LangChain</a>
          
          
             
          
        
          
            <a href="/notes/blog/category/rag"> <i class="fa-solid fa-tag fa-sm"></i> RAG</a>
          
          
        
      
    </p>
  </header>

  <article class="post-content">
    
    <div id="markdown-content">
      <h1 id="chat-models">Chat Models</h1>

<ul>
  <li>Chat models are language models that use a sequence of messages as inputs and return messages as outputs.</li>
</ul>

<h2 id="overview">Overview</h2>

<ul>
  <li>
    <p>LLMs are advanced machine learning models that excel in a wide range of language-related tasks such as text generation, translation, summarization, question answering and more without needing task specific fine tuning for every scenario.</p>
  </li>
  <li>
    <p>Modern LLMs are typically accessed through a chat model interface that takes a list of messages as input and returns a message as output.</p>
  </li>
</ul>

<ol>
  <li>Tool calling: Many popular chat models offer a native tool calling API. This API allows developers to build rich applications that enable LLMs to interact with external services, APIs, and databases. Tool calling can also be used to extract structured information from unstructured data and perform various other tasks.</li>
  <li>Structured output: A technique to make a chat model respond in a structured format, such as JSON that matches a given schema.</li>
  <li>Multimodality: The ability to work with data other than text; for example, images, audio, and video.</li>
</ol>

<h2 id="features">Features</h2>

<ul>
  <li>LangChain provides a consistent interface for working with chat models from different providers while offering additional features for monitoring, debugging, and optimizing the performance of applications that use LLMs.</li>
</ul>

<ol>
  <li>Integrations with many chat model providers (e.g., Anthropic, OpenAI, Ollama, Microsoft Azure, Google Vertex, Amazon Bedrock, Hugging Face, Cohere, Groq). Please see chat model integrations for an up-to-date list of supported models.</li>
  <li>Use either LangChain’s messages format or OpenAI format.</li>
  <li>Standard tool calling API: standard interface for binding tools to models, accessing tool call requests made by models, and sending tool results back to the model.</li>
  <li>Standard API for structuring outputs via the with_structured_output method.</li>
  <li>Provides support for async programming, efficient batching, a rich streaming API.</li>
  <li>Integration with LangSmith for monitoring and debugging production-grade applications based on LLMs.</li>
  <li>Additional features like standardized token usage, rate limiting, caching and more.</li>
</ol>

<h2 id="interface">Interface</h2>

<ul>
  <li>
    <p>LangChain chat models implement the BaseChatModel interface. Because BaseChatModel also implements the Runnable Interface, chat models support a standard streaming interface, async programming, optimized batching, and more. Please see the Runnable Interface for more details.</p>
  </li>
  <li>
    <p>Many of the key methods of chat models operate on messages as input and return messages as output.</p>
  </li>
  <li>
    <p>Chat models offer a standard set of parameters that can be used to configure the model. These parameters are typically used to control the behavior of the model, such as the temperature of the output, the maximum number of tokens in the response, and the maximum time to wait for a response.</p>
  </li>
</ul>

<h2 id="key-methods">key methods:</h2>

<ol>
  <li>
    <p>invoke: the primary method for interacting with a chat model. takes a list of messages and then returns a list of messages</p>
  </li>
  <li>
    <p>stream: allows you to stream the output of a chat model as it is generated.</p>
  </li>
  <li>
    <p>bind_tools: A method that allows you to bind a tool to a chat model for usr in the model’s execution context.</p>
  </li>
  <li>
    <p>batch: allows you to batch multiple requests to a chat model together for more efficient processing</p>
  </li>
  <li>
    <p>with_structured_output: A wrapper around invoke method for models that natively support structured output.</p>
  </li>
</ol>

<h2 id="context-window">Context window</h2>

<ul>
  <li>
    <p>A chat model’s context window refers to the maximum size of the input sequence the model can process at one time.</p>
  </li>
  <li>
    <p>the size of the input is measured in tokens which are the unit of processing th e model uses.</p>
  </li>
</ul>

<h2 id="rate-limiting">Rate-limiting</h2>

<ul>
  <li>many chat model providers impose a limit on the number of requests that can be made in a given time period/</li>
</ul>

<p>avoid it by:</p>

<ol>
  <li>
    <p>avoid hitting rate limits by spacing out requests. rate_limiter parameter</p>
  </li>
  <li>
    <p>try to recover from rate limit errors</p>
  </li>
  <li>
    <p>fallback to another chat model</p>
  </li>
</ol>

<h2 id="caching">Caching</h2>

<ul>
  <li>
    <p>Chat model APIs can be slow, so we can cache the results of previous conversations.</p>
  </li>
  <li>
    <p>An alternative approach is to use semantic caching, where you cache responses based on the meaning of the input rather than the exact input itself. This can be effective in some situations, but not in others.</p>
  </li>
  <li>
    <p>A semantic cache introduces a dependency on another model on the critical path of your application (e.g., the semantic cache may rely on an embedding model to convert text to a vector representation), and it’s not guaranteed to capture the meaning of the input accurately.</p>
  </li>
  <li>
    <p>However, there might be situations where caching chat model responses is beneficial. For example, if you have a chat model that is used to answer frequently asked questions, caching responses can help reduce the load on the model provider, costs, and improve response times.</p>
  </li>
</ul>

<h2 id="reference">Reference</h2>

<p>https://python.langchain.com/docs/concepts/chat_models/</p>

    </div>
  </article>

  

  

  
    
  

  
  
</div>
</div>
          </div>
        
      
    </div>

    <!-- Footer -->
    


  <footer class="sticky-bottom mt-5" role="contentinfo">
    

    <div class="container">
      
  © Copyright 2025
  Neural
  
  Notes. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme.

  
  
    Last updated: November 27, 2025.
  

    </div>
  </footer>



    <!-- JavaScripts -->
    <!-- jQuery -->
<script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

<!-- Bootsrap & MDB scripts -->
<script src="/notes/assets/js/bootstrap.bundle.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>


  <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="" integrity="" crossorigin="anonymous"></script>
  <script defer src="/notes/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script>























  <!-- Medium Zoom JS -->
  <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script>
  <script defer src="/notes/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script>



  <!-- Sidebar Table of Contents -->
  <script defer src="/notes/assets/js/bootstrap-toc.min.js?c82ff4de8b0955d6ff14f5b05eed7eb6"></script>




<!-- Load Common JS -->
<script src="/notes/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script>
<script defer src="/notes/assets/js/common.js?c15de51d4bb57887caa2c21988d97279"></script>
<script defer src="/notes/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script>

<!-- Jupyter Open External Links New Tab -->
<script defer src="/notes/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script>

<!-- Badges -->




  <!-- MathJax -->
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script>
  
    <script src="/notes/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script>
    <script defer src="" crossorigin="anonymous"></script>
  









  <!-- Scrolling Progress Bar -->
  <script defer src="/notes/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script>







  <!-- Back to Top -->
  <script src="/notes/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script>
  <script>
    addBackToTop();
  </script>



  <!-- Search -->
  <script type="module" src="/notes/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script>
  <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys>
  <script src="/notes/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script>
  <script src="/notes/assets/js/search-data.js"></script>
  <script src="/notes/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script>




  </body>
</html>
